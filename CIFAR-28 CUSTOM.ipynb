{"cells":[{"cell_type":"code","execution_count":null,"id":"b8da3c22-5f5c-4e56-ac98-2284e7728b9d","metadata":{"id":"b8da3c22-5f5c-4e56-ac98-2284e7728b9d"},"outputs":[],"source":["import torch\n","from torch import nn\n","\n","import numpy as np\n","from PIL import Image\n","import torch.optim as optim\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision import models\n","from tqdm import tqdm\n","import os"]},{"cell_type":"code","execution_count":null,"id":"ba6a9e29-4a07-49c1-8b6d-8d73be2b8cdd","metadata":{"id":"ba6a9e29-4a07-49c1-8b6d-8d73be2b8cdd"},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n","    # transforms.Resize(224,224)\n","])"]},{"cell_type":"code","execution_count":null,"id":"acb7ee13-8a69-4f45-b376-ad3835bdc187","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acb7ee13-8a69-4f45-b376-ad3835bdc187","executionInfo":{"status":"ok","timestamp":1739177144009,"user_tz":480,"elapsed":8335,"user":{"displayName":"Memes Lover","userId":"14679802269873994244"}},"outputId":"e16595a1-54e0-41d3-9de3-a9c81db6f158"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 169M/169M [00:03<00:00, 45.9MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/cifar-100-python.tar.gz to data\n","Files already downloaded and verified\n"]}],"source":["train_data = torchvision.datasets.CIFAR100(root='data',download = True,transform = transform,train = True)\n","test_data = torchvision.datasets.CIFAR100(root='data',download = True,transform = transform,train = False)"]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import torchvision\n","from torchvision.datasets import CIFAR100\n","import torchvision.transforms as transforms\n","import os\n","\n","# Define selected class indices\n","selected_classes = [0, 8, 9, 10, 11, 13, 16, 20, 22, 23, 25, 28, 35, 37, 39, 40, 46, 48, 50, 53, 61, 68, 79, 82, 84, 86, 87, 98]\n","\n","# Create a mapping from old labels to new labels\n","class_map = {old_label: new_label for new_label, old_label in enumerate(selected_classes)}\n","\n","# Custom CIFAR-100 Dataset\n","class CustomCIFAR100(CIFAR100):\n","    def __init__(self, root, train=True, transform=None, download=False, selected_classes=None):\n","        super().__init__(root=root, train=train, download=download)\n","        self.transform = transform  # ✅ Store transform function\n","\n","        if selected_classes is not None:\n","            # ✅ Filter dataset based on selected classes\n","            indices = [i for i, label in enumerate(self.targets) if label in selected_classes]\n","            self.data = np.array(self.data)[indices]  # Convert to NumPy array for slicing\n","            self.targets = np.array([self.targets[i] for i in indices])\n","\n","            # ✅ Remap labels (old CIFAR-100 labels → new 0 to 27 labels)\n","            self.class_map = {old_label: new_label for new_label, old_label in enumerate(selected_classes)}\n","            self.targets = np.array([self.class_map[label] for label in self.targets])\n","\n","        self.classes = [self.classes[i] for i in selected_classes]  # ✅ Update class names\n","\n","    def __getitem__(self, index):\n","        img, target = self.data[index], self.targets[index]\n","\n","        # ✅ Apply transform directly to the image data (NumPy array or PIL Image)\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        return img, target\n","\n","# ✅ Define transformation\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","# ✅ Create new datasets\n","train_custom = CustomCIFAR100(root='./data', train=True, transform=transform, download=True, selected_classes=selected_classes)\n","test_custom = CustomCIFAR100(root='./data', train=False, transform=transform, download=True, selected_classes=selected_classes)\n","\n","# ✅ Print dataset size\n","print(f\"Filtered Train Dataset Size: {len(train_custom)}\")\n","print(f\"Filtered Test Dataset Size: {len(test_custom)}\")\n","\n","# ✅ Verify class distribution\n","print(f\"Unique classes in new train dataset: {set(train_custom.targets)}\")\n","print(f\"Unique classes in new test dataset: {set(test_custom.targets)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LM_yVTx3-CSh","executionInfo":{"status":"ok","timestamp":1739177146218,"user_tz":480,"elapsed":2213,"user":{"displayName":"Memes Lover","userId":"14679802269873994244"}},"outputId":"7b8c624e-6fe7-40dd-8ffc-73ff3ff833c2"},"id":"LM_yVTx3-CSh","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Filtered Train Dataset Size: 14000\n","Filtered Test Dataset Size: 2800\n","Unique classes in new train dataset: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27}\n","Unique classes in new test dataset: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27}\n"]}]},{"cell_type":"code","execution_count":null,"id":"048ebe8c-e342-4f90-8b98-1c6e462f1451","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"048ebe8c-e342-4f90-8b98-1c6e462f1451","executionInfo":{"status":"ok","timestamp":1739177146288,"user_tz":480,"elapsed":38,"user":{"displayName":"Memes Lover","userId":"14679802269873994244"}},"outputId":"1d9da2c3-53a4-499a-bcf1-e9de9bf91b90"},"outputs":[{"output_type":"stream","name":"stdout","text":["CIFAR-100 Classes (filtered):\n","[0, 8, 9, 10, 11, 13, 16, 20, 22, 23, 25, 28, 35, 37, 39, 40, 46, 48, 50, 53, 61, 68, 79, 82, 84, 86, 87, 98] 28\n"]}],"source":["class_names = selected_classes  # List of selected class names\n","\n","print(\"CIFAR-100 Classes (filtered):\")\n","print(class_names, len(class_names))"]},{"cell_type":"code","execution_count":null,"id":"1cf9c1dc-7d2b-4d06-90c6-e033f6e0db25","metadata":{"id":"1cf9c1dc-7d2b-4d06-90c6-e033f6e0db25"},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(\n","    train_custom,\n","    batch_size = 64,\n","    shuffle=  True,\n","    num_workers = 2\n",")\n","test_loader = torch.utils.data.DataLoader(\n","    test_custom,\n","    batch_size = 64,\n","    shuffle=  True,\n","    num_workers = 2\n",")"]},{"cell_type":"code","execution_count":null,"id":"002b217b-f5ee-4092-9e25-fddae21b92af","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"002b217b-f5ee-4092-9e25-fddae21b92af","executionInfo":{"status":"ok","timestamp":1739177146403,"user_tz":480,"elapsed":92,"user":{"displayName":"Memes Lover","userId":"14679802269873994244"}},"outputId":"a26856fe-6a94-4c46-aead-4b4212f0f6e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([[[0.9608, 0.9451, 0.9373,  ..., 0.9608, 0.9608, 0.9529],\n","         [0.9608, 0.9451, 0.9373,  ..., 0.9686, 0.9686, 0.9608],\n","         [0.9686, 0.9608, 0.9608,  ..., 0.9608, 0.9608, 0.9608],\n","         ...,\n","         [0.7333, 0.7333, 0.7647,  ..., 0.5608, 0.6235, 0.8275],\n","         [0.7647, 0.7804, 0.7961,  ..., 0.6000, 0.6627, 0.8353],\n","         [0.8275, 0.8353, 0.8431,  ..., 0.7176, 0.7490, 0.8196]],\n","\n","        [[0.9608, 0.9529, 0.9451,  ..., 0.9608, 0.9608, 0.9608],\n","         [0.9686, 0.9529, 0.9373,  ..., 0.9686, 0.9765, 0.9686],\n","         [0.9686, 0.9451, 0.9216,  ..., 0.9529, 0.9529, 0.9529],\n","         ...,\n","         [0.6706, 0.6157, 0.6235,  ..., 0.3804, 0.5137, 0.7961],\n","         [0.7490, 0.7176, 0.6941,  ..., 0.4510, 0.5765, 0.8196],\n","         [0.8275, 0.8196, 0.8039,  ..., 0.6392, 0.6941, 0.8039]],\n","\n","        [[0.9451, 0.9059, 0.8745,  ..., 0.9294, 0.9294, 0.9294],\n","         [0.9216, 0.8667, 0.8353,  ..., 0.8980, 0.9059, 0.9059],\n","         [0.9137, 0.8588, 0.8275,  ..., 0.8667, 0.8824, 0.8980],\n","         ...,\n","         [0.4980, 0.3804, 0.4196,  ..., 0.0510, 0.2941, 0.7725],\n","         [0.6000, 0.5373, 0.5686,  ..., 0.1843, 0.4118, 0.7882],\n","         [0.7725, 0.7569, 0.7647,  ..., 0.5216, 0.6235, 0.7882]]]), 0)\n","image shape = torch.Size([3, 32, 32])\n"]}],"source":["image,label = train_custom[0]\n","print(f\"{image,label}\\nimage shape = {image.shape}\")"]},{"cell_type":"code","execution_count":null,"id":"c196decc-a682-4f2d-8639-4dd27ee6fd8a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c196decc-a682-4f2d-8639-4dd27ee6fd8a","executionInfo":{"status":"ok","timestamp":1739177147634,"user_tz":480,"elapsed":1230,"user":{"displayName":"Memes Lover","userId":"14679802269873994244"}},"outputId":"36b21f5b-20f5-4a43-9e9a-7d4cc2682123"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 84.8MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=28, bias=True)\n",")"]},"metadata":{},"execution_count":9}],"source":["# Load pretrained ResNet-18 model\n","resnet_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n","\n","# Modify the final layer to match CIFAR-10 (10 classes)\n","num_features = resnet_model.fc.in_features  # Get the input size of the last layer\n","resnet_model.fc = nn.Linear(num_features, 28)  # Replace with 10 output classes\n","\n","# Move model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","resnet_model.to(device)"]},{"cell_type":"code","execution_count":null,"id":"d1c786b5-67c0-49e9-afe2-3af40bd59213","metadata":{"id":"d1c786b5-67c0-49e9-afe2-3af40bd59213"},"outputs":[],"source":["class NeuralNet(nn.Module):\n","    def __init__(self,input_shape,output_shape):\n","        super().__init__()\n","        self.conv_1 = nn.Sequential(\n","            nn.Conv2d(in_channels = input_shape,\n","                     out_channels = 12,\n","                     kernel_size = 3,\n","                     stride = 1,\n","                     padding = 1), #output size = (12,32,32)\n","            nn.LeakyReLU(),\n","            nn.BatchNorm2d(12),\n","            nn.MaxPool2d(kernel_size = 2,\n","                        stride = 2) #output = (12,16,16)\n","        )\n","        self.conv_2 = nn.Sequential(\n","            nn.Conv2d(in_channels = 12,\n","                     out_channels = 24,\n","                     kernel_size = 3,\n","                     stride = 1,\n","                     padding = 1), #output size = (24,16,16)\n","            nn.LeakyReLU(),\n","            nn.BatchNorm2d(24),\n","            nn.MaxPool2d(kernel_size = 2,\n","                        stride = 2) # output size =(24,8,8)\n","        )\n","        self.conv_3 = nn.Sequential(\n","            nn.Conv2d(in_channels = 24,\n","                     out_channels = 48,\n","                     kernel_size = 3,\n","                     stride = 1,\n","                     padding = 1), #output size = (48,8,8)\n","            nn.LeakyReLU(),\n","            nn.BatchNorm2d(48),\n","            nn.MaxPool2d(kernel_size = 2,\n","                        stride = 2) # output size =(48,4,4)\n","        )\n","        self.conv_4 = nn.Sequential(\n","            nn.Conv2d(in_channels = 48,\n","                     out_channels = 96,\n","                     kernel_size = 3,\n","                     stride = 1,\n","                     padding = 1), #output size = (96,4,4)\n","            nn.LeakyReLU(),\n","            nn.BatchNorm2d(96),\n","            nn.MaxPool2d(kernel_size = 2,\n","                        stride = 2) # output size =(96,2,2)\n","        )\n","        self.fc1 = nn.Linear( #fallten\n","            96*2*2,120\n","        )\n","        self.fc2 = nn.Linear(120,84)\n","        self.fc3 = nn.Linear(84,32)\n","        self.fc4 = nn.Linear(32,output_shape) #fc = fully connected\n","        self.dropout = nn.Dropout(0.3)\n","        self.leakyrelu = nn.LeakyReLU()\n","\n","    def forward(self,x):\n","        x = self.conv_1(x)\n","        x = self.conv_2(x)\n","        x = self.conv_3(x)\n","        x = self.conv_4(x)\n","\n","        x = torch.flatten(x,1)\n","\n","        x = self.leakyrelu(self.dropout(self.fc1(x)))\n","        x = self.leakyrelu(self.dropout(self.fc2(x)))\n","        x = self.leakyrelu(self.dropout(self.fc3(x)))\n","        x = self.dropout(self.fc4(x))\n","        return x\n","\n","\n","# class NeuralNet(nn.Module):\n","#     def __init__(self, input_shape, output_shape):\n","#         super().__init__()\n","#         self.conv_1 = nn.Sequential(\n","#             nn.Conv2d(input_shape, 64, kernel_size=3, stride=1, padding=1),\n","#             nn.LeakyReLU(),\n","#             nn.BatchNorm2d(64),\n","#             nn.MaxPool2d(2, 2)\n","#         )\n","#         self.conv_2 = nn.Sequential(\n","#             nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","#             nn.LeakyReLU(),\n","#             nn.BatchNorm2d(128),\n","#             nn.MaxPool2d(2, 2)\n","#         )\n","#         self.conv_3 = nn.Sequential(\n","#             nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n","#             nn.LeakyReLU(),\n","#             nn.BatchNorm2d(256),\n","#             nn.MaxPool2d(2, 2)\n","#         )\n","#         self.conv_4 = nn.Sequential(\n","#             nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n","#             nn.LeakyReLU(),\n","#             nn.BatchNorm2d(512),\n","#             nn.MaxPool2d(2, 2)\n","#         )\n","\n","#         self.gap = nn.AdaptiveAvgPool2d(1)  # Global Average Pooling\n","#         self.fc1 = nn.Linear(512, 256)\n","#         self.fc2 = nn.Linear(256, output_shape)\n","\n","#         self.dropout = nn.Dropout(0.3)\n","#         self.leakyrelu = nn.LeakyReLU()\n","\n","#     def forward(self, x):\n","#         x = self.conv_1(x)\n","#         x = self.conv_2(x)\n","#         x = self.conv_3(x)\n","#         x = self.conv_4(x)\n","\n","#         x = self.gap(x)  # Apply GAP\n","#         x = torch.flatten(x, 1)  # Flatten before FC layer\n","\n","#         x = self.leakyrelu(self.dropout(self.fc1(x)))\n","#         x = self.fc2(x)  # Removed dropout from last layer\n","#         return x\n"]},{"cell_type":"code","execution_count":null,"id":"6fefacd4-ab9c-4976-b08c-17292de62eba","metadata":{"id":"6fefacd4-ab9c-4976-b08c-17292de62eba"},"outputs":[],"source":["self_model = NeuralNet(3,28).to(device)"]},{"cell_type":"code","execution_count":null,"id":"84595b16-c083-4a1b-b058-a193d5f76057","metadata":{"id":"84595b16-c083-4a1b-b058-a193d5f76057"},"outputs":[],"source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer_self = optim.SGD(self_model.parameters(), lr=0.001, momentum=0.9)\n","optimizer_resnet = optim.SGD(resnet_model.parameters(),lr = 0.001,momentum = 0.9)"]},{"cell_type":"code","execution_count":null,"id":"f82c4c78-066b-469a-b64b-958d954f4d5e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"f82c4c78-066b-469a-b64b-958d954f4d5e","executionInfo":{"status":"error","timestamp":1739179597653,"user_tz":480,"elapsed":41673,"user":{"displayName":"Memes Lover","userId":"14679802269873994244"}},"outputId":"e16fae23-baab-441a-88a0-6421bd4475a9"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-67-936782af7091>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(checkpoint_path)\n"]},{"output_type":"stream","name":"stdout","text":["Resuming training from epoch 7\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/63 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 7...\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 1/63 [00:02<02:55,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/70, Loss: 0.0209, Checkpoint saved!\n","loss: 0.0209 \n","Training epoch: 8...\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 2/63 [00:06<03:11,  3.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/70, Loss: 0.0209, Checkpoint saved!\n","loss: 0.0209 \n","Training epoch: 9...\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▍         | 3/63 [00:08<02:51,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/70, Loss: 0.0209, Checkpoint saved!\n","loss: 0.0209 \n","Training epoch: 10...\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▋         | 4/63 [00:11<02:42,  2.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 11/70, Loss: 0.0209, Checkpoint saved!\n","loss: 0.0209 \n","Training epoch: 11...\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 5/63 [00:13<02:35,  2.67s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 12/70, Loss: 0.0210, Checkpoint saved!\n","loss: 0.0210 \n","Training epoch: 12...\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|▉         | 6/63 [00:16<02:40,  2.81s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 13/70, Loss: 0.0209, Checkpoint saved!\n","loss: 0.0209 \n","Training epoch: 13...\n"]},{"output_type":"stream","name":"stderr","text":["\r 11%|█         | 7/63 [00:20<02:42,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 14/70, Loss: 0.0209, Checkpoint saved!\n","loss: 0.0209 \n","Training epoch: 14...\n"]},{"output_type":"stream","name":"stderr","text":["\r 13%|█▎        | 8/63 [00:22<02:32,  2.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 15/70, Loss: 0.0209, Checkpoint saved!\n","loss: 0.0209 \n","Training epoch: 15...\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 9/63 [00:25<02:26,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 16/70, Loss: 0.0209, Checkpoint saved!\n","loss: 0.0209 \n","Training epoch: 16...\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 10/63 [00:27<02:20,  2.66s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 17/70, Loss: 0.0209, Checkpoint saved!\n","loss: 0.0209 \n","Training epoch: 17...\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 11/63 [00:30<02:29,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 18/70, Loss: 0.0209, Checkpoint saved!\n","loss: 0.0209 \n","Training epoch: 18...\n"]},{"output_type":"stream","name":"stderr","text":["\r 19%|█▉        | 12/63 [00:33<02:23,  2.80s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 19/70, Loss: 0.0210, Checkpoint saved!\n","loss: 0.0210 \n","Training epoch: 19...\n"]},{"output_type":"stream","name":"stderr","text":["\r 21%|██        | 13/63 [00:36<02:16,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 20/70, Loss: 0.0209, Checkpoint saved!\n","loss: 0.0209 \n","Training epoch: 20...\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 14/63 [00:38<02:11,  2.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 21/70, Loss: 0.0209, Checkpoint saved!\n","loss: 0.0209 \n","Training epoch: 21...\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 15/63 [00:41<02:08,  2.67s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 22/70, Loss: 0.0209, Checkpoint saved!\n","loss: 0.0209 \n","Training epoch: 22...\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 15/63 [00:41<02:12,  2.77s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-67-936782af7091>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["start_epoch = 0\n","checkpoint_path = \"Models/checkpoint.pth\"\n","if os.path.exists(checkpoint_path):\n","    checkpoint = torch.load(checkpoint_path)\n","    self_model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer_self.load_state_dict(checkpoint['optimizer_state_dict'])\n","    start_epoch = checkpoint['epoch'] + 1\n","    print(f\"Resuming training from epoch {start_epoch}\")\n","else:\n","    print(\"No checkpoint found. Starting fresh.\")\n","\n","EPOCHS = 70\n","for epoch in tqdm(range(start_epoch,EPOCHS)):\n","    print(f\"Training epoch: {epoch}...\")\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(train_loader):\n","\n","        input,labels = data\n","        input,labels = input.to(device),labels.to(device)\n","        optimizer_self.zero_grad()\n","        outputs = self_model(input)\n","\n","\n","        loss = loss_fn(outputs,labels)\n","        loss.backward()\n","        optimizer_self.step()\n","        running_loss += loss.item()\n","\n","    checkpoint = {\n","            'epoch': epoch,\n","            'model_state_dict': self_model.state_dict(),\n","            'optimizer_state_dict': optimizer_self.state_dict(),\n","        }\n","    torch.save(checkpoint, checkpoint_path)\n","    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {running_loss/len(train_loader):.4f}, Checkpoint saved!\")\n","\n","    print(f\"loss: {running_loss/len(train_loader):.4f} \")"]},{"cell_type":"code","execution_count":null,"id":"384ae25a-a389-46d6-a5e2-1ddcb49e5292","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":723},"id":"384ae25a-a389-46d6-a5e2-1ddcb49e5292","executionInfo":{"status":"error","timestamp":1739179639778,"user_tz":480,"elapsed":27134,"user":{"displayName":"Memes Lover","userId":"14679802269873994244"}},"outputId":"f2de1ddd-7fba-4aeb-d869-6082bf52a4ac"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-68-0d9f1cfcd274>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(checkpoint_path)\n"]},{"output_type":"stream","name":"stdout","text":["Resuming training from epoch 21\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/9 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Training epoch: 21...\n"]},{"output_type":"stream","name":"stderr","text":["\r 11%|█         | 1/9 [00:04<00:36,  4.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 22/30, Loss: 0.0387, Checkpoint saved!\n","loss: 0.0387 \n","Training epoch: 22...\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 2/9 [00:09<00:32,  4.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 23/30, Loss: 0.0402, Checkpoint saved!\n","loss: 0.0402 \n","Training epoch: 23...\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 3/9 [00:14<00:28,  4.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 24/30, Loss: 0.0211, Checkpoint saved!\n","loss: 0.0211 \n","Training epoch: 24...\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 4/9 [00:18<00:23,  4.65s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 25/30, Loss: 0.0040, Checkpoint saved!\n","loss: 0.0040 \n","Training epoch: 25...\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 5/9 [00:23<00:19,  4.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch 26/30, Loss: 0.0009, Checkpoint saved!\n","loss: 0.0009 \n","Training epoch: 26...\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 5/9 [00:26<00:21,  5.39s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-68-0d9f1cfcd274>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer_resnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1700\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["start_epoch = 0\n","checkpoint_path = \"Models/checkpoint_resnet_1.pth\"\n","if os.path.exists(checkpoint_path):\n","    checkpoint = torch.load(checkpoint_path)\n","    resnet_model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer_resnet.load_state_dict(checkpoint['optimizer_state_dict'])\n","    start_epoch = checkpoint['epoch'] + 1\n","    print(f\"Resuming training from epoch {start_epoch}\")\n","else:\n","    print(\"No checkpoint found. Starting fresh.\")\n","\n","EPOCHS = 30\n","for epoch in tqdm(range(start_epoch,EPOCHS)):\n","    print(f\"Training epoch: {epoch}...\")\n","\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(train_loader):\n","        input,labels = data\n","        input,labels = input.to(device),labels.to(device)\n","        optimizer_resnet.zero_grad()\n","        outputs = resnet_model(input)\n","\n","        loss = loss_fn(outputs,labels)\n","        loss.backward()\n","        optimizer_resnet.step()\n","        running_loss += loss.item()\n","    checkpoint = {\n","            'epoch': epoch,\n","            'model_state_dict': resnet_model.state_dict(),\n","            'optimizer_state_dict': optimizer_resnet.state_dict(),\n","        }\n","    torch.save(checkpoint, checkpoint_path)\n","    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {running_loss/len(train_loader):.4f}, Checkpoint saved!\")\n","    print(f\"loss: {running_loss/len(train_loader):.4f} \")"]},{"cell_type":"code","execution_count":null,"id":"e3346db7-ca8a-41c2-be28-da3710dce83e","metadata":{"id":"e3346db7-ca8a-41c2-be28-da3710dce83e"},"outputs":[],"source":["torch.save(self_model.state_dict(),'Models/trained_self.pth')\n","torch.save(resnet_model.state_dict(),'Models/trained_resnet.pth')"]},{"cell_type":"code","execution_count":null,"id":"bbd3f8fa-5b6c-4f9d-a7f2-f8edd15095c4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bbd3f8fa-5b6c-4f9d-a7f2-f8edd15095c4","executionInfo":{"status":"ok","timestamp":1739179645513,"user_tz":480,"elapsed":333,"user":{"displayName":"Memes Lover","userId":"14679802269873994244"}},"outputId":"290ab238-def1-49fd-97bb-1692f4a33adb"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-70-41c3f4603223>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  self_model.load_state_dict(torch.load('Models/trained_self.pth'))\n","<ipython-input-70-41c3f4603223>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  resnet_model.load_state_dict(torch.load('Models/trained_resnet.pth'))\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":70}],"source":["self_model = NeuralNet(3,len(train_data.classes)).to(device)\n","self_model.load_state_dict(torch.load('Models/trained_self.pth'))\n","resnet_model = resnet_model.to(device)\n","resnet_model.load_state_dict(torch.load('Models/trained_resnet.pth'))"]},{"cell_type":"code","execution_count":null,"id":"96462181-2484-425e-b7c2-5486a4eca741","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"96462181-2484-425e-b7c2-5486a4eca741","executionInfo":{"status":"ok","timestamp":1739179648872,"user_tz":480,"elapsed":493,"user":{"displayName":"Memes Lover","userId":"14679802269873994244"}},"outputId":"53f6ed7e-b2ac-4f7b-c4fc-4960fee5141a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 62.07%\n","Validation Loss: 1.8443\n"]}],"source":["correct = 0\n","total = 0\n","total_loss = 0  # Track loss\n","self_model.eval()\n","criterion = nn.CrossEntropyLoss()  # Define loss function\n","\n","with torch.no_grad():  # Use torch.no_grad() for better compatibility\n","    for images, labels in test_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        outputs = self_model(images)\n","        loss = criterion(outputs, labels)  # Compute loss\n","        total_loss += loss.item() * labels.size(0)  # Scale loss properly\n","\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","# Compute final metrics\n","accuracy = 100 * correct / total\n","average_loss = total_loss / total  # Correct loss averaging\n","\n","print(f\"Test Accuracy: {accuracy:.2f}%\")\n","print(f\"Validation Loss: {average_loss:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"d828d727-f0ba-4a06-bf33-1a8907d2e06c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d828d727-f0ba-4a06-bf33-1a8907d2e06c","executionInfo":{"status":"ok","timestamp":1739179654005,"user_tz":480,"elapsed":567,"user":{"displayName":"Memes Lover","userId":"14679802269873994244"}},"outputId":"6d4cadba-60ba-45c4-e7af-aa3e4aba42d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 69.54%\n","Validation Loss: 2.1186\n"]}],"source":["correct = 0\n","total = 0\n","total_loss = 0  # Track loss\n","\n","resnet_model.eval()\n","criterion = nn.CrossEntropyLoss()  # Define loss function\n","\n","with torch.inference_mode():\n","    for data in test_loader:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","\n","        outputs = resnet_model(images)\n","        loss = criterion(outputs, labels)  # Compute loss\n","        total_loss += loss.item()  # Accumulate loss\n","\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","# Compute final metrics\n","accuracy = 100 * correct / total\n","average_loss = total_loss / len(test_loader)  # Compute average loss\n","\n","print(f\"Test Accuracy: {accuracy:.2f}%\")\n","print(f\"Validation Loss: {average_loss:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"74cf1f87-e1e0-45ba-8e2f-4ec62b672c43","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"74cf1f87-e1e0-45ba-8e2f-4ec62b672c43","executionInfo":{"status":"ok","timestamp":1739180089072,"user_tz":480,"elapsed":855,"user":{"displayName":"Memes Lover","userId":"14679802269873994244"}},"outputId":"d4b0e2e7-c680-4ad2-d0de-ca9fd1ed02b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction: 0\n","Prediction: 8\n","Prediction: 9\n","Prediction: 10\n","Prediction: 22\n","Prediction: 50\n","Prediction: 39\n"]}],"source":["new_transform = transforms.Compose([\n","    transforms.Resize((32,32)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n","])\n","\n","def load_image(image_path):\n","    image = Image.open(image_path)\n","    image = new_transform(image)\n","    image = image.unsqueeze(0)\n","    return image\n","\n","image_paths = ['apple.jpg','bycycle.jpg','bottle.jpg','bowl.jpg','clock.jpg','chair.jpg','keyboard.jpg']\n","images = [load_image(img) for img in image_paths]\n","\n","self_model.eval()\n","with torch.inference_mode():\n","    for image in images:\n","        image = image.to(device)\n","        output = resnet_model(image)\n","        _,predicted = torch.max(output,1)\n","        print(f\"Prediction: {class_names[predicted.item()]}\")"]},{"cell_type":"code","execution_count":null,"id":"edc892cb-3d1b-430e-a5fd-a0b84edddb76","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"edc892cb-3d1b-430e-a5fd-a0b84edddb76","executionInfo":{"status":"ok","timestamp":1739179686655,"user_tz":480,"elapsed":1114,"user":{"displayName":"Memes Lover","userId":"14679802269873994244"}},"outputId":"0c2191f2-1500-43ca-ec45-534bac9077e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction: 0\n","Prediction: 8\n","Prediction: 9\n","Prediction: 10\n","Prediction: 22\n","Prediction: 79\n","Prediction: 39\n"]}],"source":["new_transform = transforms.Compose([\n","    transforms.Resize((32,32)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n","])\n","\n","def load_image(image_path):\n","    image = Image.open(image_path)\n","    image = new_transform(image)\n","    image = image.unsqueeze(0)\n","    return image\n","\n","image_paths = ['apple.jpg','bycycle.jpg','bottle.jpg','bowl.jpg','clock.jpg','chair.jpg','keyboard.jpg']\n","images = [load_image(img) for img in image_paths]\n","\n","self_model.eval()\n","with torch.inference_mode():\n","    for image in images:\n","        image = image.to(device)\n","        output = resnet_model(image)\n","        _,predicted = torch.max(output,1)\n","        print(f\"Prediction: {class_names[predicted.item()]}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}